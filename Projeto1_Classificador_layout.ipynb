{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Augusto Rocha Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Importando as bibliotecas necess√°rias-----------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Havaianas.xlsx, tudo certo para prosseguir com o projeto!\n"
     ]
    }
   ],
   "source": [
    "#### ----------------------------------Pegando o excel com as classifica√ß√µes manuais dos tweets-------------------------------------\n",
    "\n",
    "filename = 'Havaianas.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com o projeto!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------Definindo Relevantes e Irrelevantes----------------------------------------------------\n",
    "\n",
    "train = pd.read_excel(filename)\n",
    "train_relevante = train[train['Classifica√ß√£o']==1]\n",
    "train_irrelevante = train[train['Classifica√ß√£o']==0]\n",
    "\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_relevante = test[test['Classifica√ß√£o']==1]\n",
    "test_irrelevante = test[test['Classifica√ß√£o']==0]\n",
    "\n",
    "\n",
    "#------------------------------------------Classifica as categorias-------------------------------------------------------------\n",
    "\n",
    "train['Classifica√ß√£o'] = train['Classifica√ß√£o'].astype('category')\n",
    "test['Classifica√ß√£o'] = test['Classifica√ß√£o'].astype('category')\n",
    "\n",
    "train.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']\n",
    "test.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram considerados relevantes os coment√°rios que expressavam uma cr√≠tica sobre o produto, seja ela positiva ou negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para retirada de caracteres indesejado:\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;@/\"\"‚Äú‚Äù,_]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_pronto = re.sub(pattern, '', text)\n",
    "    return text_pronto\n",
    "\n",
    "\n",
    "# Fun√ß√£o para retirada dos acentos nos textos:\n",
    "\n",
    "def tira_acentos(texto):\n",
    "    acentos = {'a':['√°', '√†', '√£', '√¢', '√§'], 'e':['√™', '√©', '√®', '√´'], 'i':['√≠', '√¨', '√Æ', '√Ø'], 'o':['√≥', '√≤', '√¥', '√µ', '√∂'], 'u':['√∫', '√π', '√ª', '√º'], 'c':['√ß']} \n",
    "    for l in acentos:\n",
    "        for e in acentos[l]:\n",
    "            texto = texto.replace(e, l)\n",
    "    return texto\n",
    "\n",
    "\n",
    "#----------------------------Cria uma string com todas as palavras e caracteres da parte de Treinamento-------------------------\n",
    "\n",
    "tweets_train = ''\n",
    "for i in range(len(train)):\n",
    "    tweets_train += train['Treinamento'].loc[i] + ' '\n",
    "\n",
    "train_limpo = tira_acentos(cleanup(tweets_train.lower()))    # Deixa a string somente com letras min√∫sculas, retira caracteres\n",
    "                                                             # indesejados e retira os acentos das letras e palavras\n",
    "\n",
    "lista_train = tweet_tokenizer.tokenize(train_limpo)    # Separa os emojis das palavras, e cria uma lista\n",
    "                                                       # em que cada palavra ou emoji √© um elemento            \n",
    "           \n",
    "tabela_t = pd.Series(lista_train).value_counts()       # Faz uma tabela com as frequ√™ncias de cada palavra na lista acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Selecionando tweets de treinamento relevantes e irrelevantes---------------------------------\n",
    "\n",
    "linhas_train_relev = train['Classifica√ß√£o'] == 'Relevante'\n",
    "df_train_relev = train.loc[linhas_train_relev, :]\n",
    "\n",
    "linhas_train_irrelev = train['Classifica√ß√£o'] == 'Irrelevante'\n",
    "df_train_irrelev = train.loc[linhas_train_irrelev, :]\n",
    "\n",
    "#------------------Juntando todos os tweets de treinamento relevantes e irrelevantes cada um numa s√≥ string---------------------\n",
    "\n",
    "tweets_train_relev = ''\n",
    "for i in df_train_relev['Treinamento']:\n",
    "    tweets_train_relev += i\n",
    "\n",
    "tweets_train_irrelev = ''\n",
    "for i in df_train_irrelev['Treinamento']:\n",
    "    tweets_train_irrelev += i\n",
    "\n",
    "    \n",
    "#----------------------------------Tornando as strings criadas acima em listas de palavras--------------------------------------\n",
    "\n",
    "lista_train_relev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_relev.lower())))\n",
    "\n",
    "lista_train_irrelev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_irrelev.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequ√™ncia ABSOLUTA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas          127\n",
      "de                  70\n",
      "e                   63\n",
      "uma                 43\n",
      "a                   37\n",
      "                  ... \n",
      "sola                 1\n",
      "6338fmdudaasb        1\n",
      "httpstcokyliygw      1\n",
      "latarcioamparo       1\n",
      "ü§≠                    1\n",
      "Length: 755, dtype: int64\n",
      "\n",
      "\n",
      "Frequ√™ncia RELATIVA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas          0.069857\n",
      "de                 0.038504\n",
      "e                  0.034653\n",
      "uma                0.023652\n",
      "a                  0.020352\n",
      "                     ...   \n",
      "sola               0.000550\n",
      "6338fmdudaasb      0.000550\n",
      "httpstcokyliygw    0.000550\n",
      "latarcioamparo     0.000550\n",
      "ü§≠                  0.000550\n",
      "Length: 755, dtype: float64\n",
      "\n",
      "\n",
      "Frequ√™ncia ABSOLUTA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas    120\n",
      "de            93\n",
      "e             73\n",
      "que           43\n",
      "a             37\n",
      "            ... \n",
      "httpstcoe      1\n",
      "canto          1\n",
      "carnaval       1\n",
      "te             1\n",
      "gnt            1\n",
      "Length: 1048, dtype: int64\n",
      "\n",
      "\n",
      "Frequ√™ncia RELATIVA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas    0.053074\n",
      "de           0.041132\n",
      "e            0.032287\n",
      "que          0.019018\n",
      "a            0.016364\n",
      "               ...   \n",
      "httpstcoe    0.000442\n",
      "canto        0.000442\n",
      "carnaval     0.000442\n",
      "te           0.000442\n",
      "gnt          0.000442\n",
      "Length: 1048, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#------------------------------Frequ√™ncias para os tweets de treino relevantes--------------------------------------------------\n",
    "\n",
    "tabela_tra = pd.Series(lista_train_relev).value_counts()\n",
    "tabela_trr = pd.Series(lista_train_relev).value_counts(True)\n",
    "\n",
    "print('Frequ√™ncia ABSOLUTA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_tra)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia RELATIVA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_trr)   # tabela printada √† t√≠tulo de consulta, pois n√£o ser√° usada posteriormente\n",
    "\n",
    "\n",
    "#------------------------------Frequ√™ncias para os tweets de treino irrelevantes------------------------------------------------\n",
    "\n",
    "tabela_tia = pd.Series(lista_train_irrelev).value_counts()\n",
    "tabela_tir = pd.Series(lista_train_irrelev).value_counts(True)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia ABSOLUTA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tia)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia RELATIVA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tir)   # tabela printada √† t√≠tulo de consulta, pois n√£o ser√° usada posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classifica√ß√£o\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante\n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante\n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante\n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante\n",
       "4    [menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...     Relevante\n",
       "..                                                 ...           ...\n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante\n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante\n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante\n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante\n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------Limpando os tweets de teste e transformando-os em listas linha a linha--------------------------------\n",
    "\n",
    "teste_em_listas = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test['Teste'])):\n",
    "    teste_em_listas.loc[i, 'Teste'] = tira_acentos(cleanup(test['Teste'][i].lower()))\n",
    "    teste_em_listas.loc[i, 'Teste'] = tweet_tokenizer.tokenize(teste_em_listas.loc[i, 'Teste'])\n",
    "\n",
    "teste_em_listas['Classifica√ß√£o'] = test['Classifica√ß√£o']\n",
    "teste_em_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explica√ß√£o dos par√¢metros usados nas seguintes fun√ß√µes:\n",
    "#   tab_abs: tabela de frequ√™ncias absolutas\n",
    "#   lista_de_pal: lista de palavras que ser√° usada\n",
    "#   tab_tds_palavras: tabela que cont√©m todas as palavras poss√≠veis\n",
    "#   tab_abs_rel: tabela de frequ√™ncias absolutas para os tweets relevantes\n",
    "#   tab_abs_irr: tabela de frequ√™ncias absolutas para os tweets irrelevantes\n",
    "#   lista_rel: lista de palavras dos tweets relevantes\n",
    "#   lista_irr: lista de palavras dos tweets irrelevantes\n",
    "\n",
    "\n",
    "# Fun√ß√£o para realizar o c√°lculo de probabilidades das palavras\n",
    "\n",
    "def probabilidade_tweet(tweet, tab_abs, lista_de_pal, tab_tds_palavras):\n",
    "    prob = 1\n",
    "    for palavra in tweet:\n",
    "        if not palavra in tab_abs:                                      # Se a palavra de teste n√£o consta em treinamento,\n",
    "            prob = prob / (len(lista_de_pal) + len(tab_tds_palavras))   # ent√£o de acordo com a suaviza√ß√£o de LaPlace\n",
    "                                                                        # a probabilidade dessa palavra fica com numerador 1\n",
    "        else:\n",
    "            prob = prob * (tab_abs['%s'%(palavra)] + 1) / (len(lista_de_pal) + len(tab_tds_palavras))\n",
    "    return prob\n",
    "\n",
    "\n",
    "# Fun√ß√£o que compara a probabilidade de ser relevante com n√£o relevante e devolve a resposta:\n",
    "\n",
    "def classifica(tweet, tab_abs_rel, tab_abs_irr, lista_rel, lista_irr, tab_tds_palavras):\n",
    "    if probabilidade_tweet(tweet, tab_abs_rel, lista_rel, tab_tds_palavras) > probabilidade_tweet(tweet, tab_abs_irr, lista_irr, tab_tds_palavras):\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classifica√ß√£o  \\\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante   \n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante   \n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante   \n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante   \n",
       "4    [menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...     Relevante   \n",
       "..                                                 ...           ...   \n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante   \n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante   \n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante   \n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante   \n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante   \n",
       "\n",
       "     Performance  \n",
       "0      Relevante  \n",
       "1      Relevante  \n",
       "2      Relevante  \n",
       "3      Relevante  \n",
       "4      Relevante  \n",
       "..           ...  \n",
       "195    Relevante  \n",
       "196    Relevante  \n",
       "197    Relevante  \n",
       "198    Relevante  \n",
       "199  Irrelevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Adicionando uma nova coluna ao dataframe Teste--------------------------------------------\n",
    "\n",
    "teste_em_listas['Performance'] = 'NaN'\n",
    "for i in range(len(teste_em_listas)):\n",
    "    teste_em_listas.loc[i, 'Performance'] = classifica(teste_em_listas.loc[i, 'Teste'], tabela_tra, tabela_tia, lista_train_relev, lista_train_irrelev, tabela_t)\n",
    "teste_em_listas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Contando o percentual de acertos----------------------------------------------------------\n",
    "\n",
    "contador = 0\n",
    "for i in range(len(teste_em_listas)):\n",
    "    if teste_em_listas.loc[i, 'Classifica√ß√£o'] == teste_em_listas.loc[i, 'Performance']:\n",
    "        contador += 1\n",
    "contador = contador / len(teste_em_listas)\n",
    "    \n",
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Performance</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Performance    Irrelevante  Relevante    All\n",
       "Classifica√ß√£o                               \n",
       "Irrelevante           0.28      0.265  0.545\n",
       "Relevante             0.11      0.345  0.455\n",
       "All                   0.39      0.610  1.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------Dashboard para an√°lise de sentimento e visualiza√ß√£o de dados-------------------------------------------\n",
    "\n",
    "quadro = pd.crosstab(teste_em_listas['Classifica√ß√£o'], teste_em_listas['Performance'], margins = True, normalize = True)\n",
    "quadro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela acima, √© poss√≠vel ver que obtemos as seguintes porcentagens:\n",
    "* Verdadeiros positivos (mensagens relevantes e que s√£o classificadas como relevantes): 34,5%\n",
    "* Falsos positivos (mensagens irrelevantes e que s√£o classificadas como relevantes): 26,5%\n",
    "* Verdadeiros negativos (mensagens irrelevantes e que s√£o classificadas como irrelevantes): 28%\n",
    "* Falsos negativos (mensagens relevantes e que s√£o classificadas como irrelevantes): 11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca que ser√° usada nessa se√ß√£o do projeto:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = pd.read_excel(filename, sheet_name = 'Todos')                # dataframe com os 500 tweets juntos\n",
    "lista_percentuais = []                                   # lista que servir√° para montar o histograma\n",
    "\n",
    "\n",
    "# Abaixo, foi feita uma fun√ß√£o que devolve o percentual de acertos para cada nova separa√ß√£o dos tweets entre\n",
    "# Treinamento e Teste. Por essa fun√ß√£o sintetizar o que foi trabalhado ao longo desse jupyter notebook,\n",
    "# a maioria dos comandos nela presentes j√° foram explicados nas c√©lulas acima.\n",
    "\n",
    "def devolve_percentual_de_acertos(df):\n",
    "    df_train, df_test = train_test_split(df, train_size=0.6)    # Separa√ß√£o de maneira aleat√≥ria dos tweets entre\n",
    "                                                                # Treinamento e Teste, sendo que a parte de Treinamento\n",
    "                                                                # fica com 60% dos tweets e a parte de Teste fica com 40%\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)    # Resetando os √≠ndices das linhas do dataframe para facilitar a sua\n",
    "    df_test = df_test.reset_index(drop=True)      # manipula√ß√£o. Os √≠ndices nesse caso n√£o s√£o importantes.\n",
    "    \n",
    "    df_train_relevante = df_train[df_train['Classifica√ß√£o']==1]\n",
    "    df_train_irrelevante = df_train[df_train['Classifica√ß√£o']==0]\n",
    "\n",
    "    df_test_relevante = df_test[df_test['Classifica√ß√£o']==1]\n",
    "    df_test_irrelevante = df_test[df_test['Classifica√ß√£o']==0]\n",
    "    \n",
    "    df_train['Classifica√ß√£o'] = df_train['Classifica√ß√£o'].astype('category')\n",
    "    df_test['Classifica√ß√£o'] = df_test['Classifica√ß√£o'].astype('category')\n",
    "\n",
    "    df_train.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']\n",
    "    df_test.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']\n",
    "\n",
    "    tweets_df_train = ''\n",
    "    for i in range(len(df_train)):\n",
    "        tweets_df_train += df_train['Tweet'].loc[i]\n",
    "\n",
    "    df_train_limpo = tira_acentos(cleanup(tweets_df_train.lower()))\n",
    "    lista_df_train = tweet_tokenizer.tokenize(df_train_limpo)\n",
    "           \n",
    "    tab_t = pd.Series(lista_df_train).value_counts()\n",
    "    \n",
    "    linhas_df_train_rel = df_train['Classifica√ß√£o'] == 'Relevante'\n",
    "    df_train_rel = df_train.loc[linhas_df_train_rel, :]\n",
    "\n",
    "    linhas_df_train_irr = df_train['Classifica√ß√£o'] == 'Irrelevante'\n",
    "    df_train_irr = df_train.loc[linhas_df_train_irr, :]\n",
    "\n",
    "    tweets_df_train_rel = ''\n",
    "    for i in df_train_rel['Tweet']:\n",
    "        tweets_df_train_rel += i\n",
    "\n",
    "    tweets_df_train_irr = ''\n",
    "    for i in df_train_irr['Tweet']:\n",
    "        tweets_df_train_irr += i\n",
    "\n",
    "    lista_df_train_rel = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_df_train_rel.lower())))\n",
    "    lista_df_train_irr = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_df_train_irr.lower())))\n",
    "    \n",
    "    tab_tra = pd.Series(lista_df_train_rel).value_counts()\n",
    "    tab_tia = pd.Series(lista_df_train_irr).value_counts()\n",
    "    \n",
    "    \n",
    "    df_test_em_listas = pd.DataFrame()\n",
    "    for i in range(len(df_test['Tweet'])):\n",
    "        df_test_em_listas.loc[i, 'Tweet'] = tira_acentos(cleanup(df_test['Tweet'][i].lower()))\n",
    "        df_test_em_listas.loc[i, 'Tweet'] = tweet_tokenizer.tokenize(df_test_em_listas.loc[i, 'Tweet'])\n",
    "    df_test_em_listas['Classifica√ß√£o'] = df_test['Classifica√ß√£o']\n",
    "    \n",
    "    df_test_em_listas['Performance'] = 'NaN'\n",
    "    for i in range(len(df_test_em_listas)):\n",
    "        df_test_em_listas.loc[i, 'Performance'] = classifica(df_test_em_listas.loc[i, 'Tweet'], tab_tra, tab_tia, lista_df_train_rel, lista_df_train_irr, tab_t)\n",
    "    \n",
    "    percentual_de_acertos = 0\n",
    "    for i in range(len(df_test_em_listas)):\n",
    "        if df_test_em_listas.loc[i, 'Classifica√ß√£o'] == df_test_em_listas.loc[i, 'Performance']:\n",
    "            percentual_de_acertos += 1\n",
    "    percentual_de_acertos = percentual_de_acertos / len(df_test_em_listas)\n",
    "    \n",
    "    return percentual_de_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetindo a fun√ß√£o definida acima 100 vezes para coletar valores de percentual\n",
    "# de acertos e ir adicionando-os um a um na minha lista\n",
    "\n",
    "for i in range(100):\n",
    "    lista_percentuais.append(devolve_percentual_de_acertos(todos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constru√ß√£o do histograma usando a lista com os percentuais de acertos para cada uma das 100 vezes em que a fun√ß√£o\n",
    "# \"devolve_percentual_de_acertos()\" foi executada, foram usadas 15 faixas nesse histograma.\n",
    "\n",
    "plt.hist(lista_percentuais, bins=15, edgecolor='white')\n",
    "plt.title('Histograma para v√°rias separa√ß√µes dos tweets entre Treinamento e Teste')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.xlabel('Percentuais de acertos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem m√©dia de acertos do meu classificador: 58.4 %\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem m√©dia de acertos do meu classificador:', (np.mean(lista_percentuais)*100).round(2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que o classificador teve uma porcentagem m√©dia de acertos de 58,46% (e de 62,5% na primeira tentativa), √© correto dizer que ele teve uma performance moderada para boa. Para tal resultado, foram essenciais algumas manipula√ß√µes, como a suaviza√ß√£o de Laplace, remo√ß√£o de caracteres indesejados (emojis s√£o mantidos), corre√ß√£o de espa√ßos entre palavras e emojis e entre os pr√≥prios emojis, e a remo√ß√£o de acentos das letras, sendo a √∫ltima, uma manipula√ß√£o extra feita por mim, que se mostrou cab√≠vel para o caso, no qual os usu√°rios n√£o precisam escrever de acordo com a norma culta da l√≠ngua portuguesa.\n",
    "\n",
    "Embora tenha fun√ß√µes de bibliotecas do python que fa√ßam a remo√ß√£o de acentos das letras, eu mesmo fiz a minha fun√ß√£o porque fun√ß√µes como unidecode() al√©m de retirar os acentos, tamb√©m removem os emojis, o que n√£o √© o nosso foco nesse classificador. Ent√£o, o que foi feito na minha fun√ß√£o foi identificar as letras que continham acentos e usar a fun√ß√£o replace() para substitu√≠-las pelas suas respectivas letras sem o acento. Os acentos considerados aqui foram o agudo, o circunflexo, o til, o grave e o trema para as vogais, e o cedilha para a letra \"c\".\n",
    "\n",
    "Analisando a √∫ltima tabela cruzada printada, vemos que a porcentagem de falsos positivos est√° bem maior que a de falsos negativos, a partir dessa informa√ß√£o, √© importante nos perguntarmos e analisarmos se o nosso classificador est√° tendencioso a classificar os tweets como relevantes. Assim, √© sempre importante reconhecer que ainda √© poss√≠vel realizar algumas melhorias no classificador em quest√£o.\n",
    "\n",
    "#### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste:\n",
    "A partir do histograma plotado acima, √© fundamental que vejamos, na constru√ß√£o de um classificador, a import√¢ncia de se considerar v√°rias divis√µes da base de dados em Treinamento e Teste, pois assim conseguimos ter uma maior no√ß√£o sobre o valor para o qual o percentual de acertos do meu classificador tende. N√£o conseguir essa ampla vis√£o da real performance do meu classificador, j√° que toda a avalia√ß√£o deste acaba sendo feita com base em uma √∫nica separa√ß√£o dos tweets entre Treinamento e Teste, se mostra como uma grande desvantagem para a constru√ß√£o de um classificador que considera apenas uma √∫nica divis√£o da base de dados em treinamento e em teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dupla nega√ß√£o e sarcasmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas caracter√≠sticas sint√°ticas da l√≠ngua portuguesa que s√£o mais pass√≠veis de classifica√ß√£o incorreta por parte de classificadores √© a dupla nega√ß√£o e o sarcasmo. Por serem particularidades sint√°ticas consagradas pelo uso, fica mais dif√≠cil atribuir ao classificador a \"interpreta√ß√£o\" necess√°ria para compreend√™-las.\n",
    "\n",
    "Essas duas caracter√≠sticas provavelmente causariam mais confus√£o numa situa√ß√£o em que se busca classificar frases positivas e negativas sobre algo, pois em frases que contenham essas figuras da linguagem, o classificador identificaria as frases como uma categoria oposta (sendo \"positivo\" oposto de \"negativo\") ao que elas realmente s√£o, justamente por causa das peculiaridades que a dupla nega√ß√£o e o sarcasmo apresentam.\n",
    "\n",
    "No nosso caso, felizmente, essa confus√£o n√£o se faz t√£o presente pois aqui o que almejamos n√£o √© classificar tweets em positivos e negativos sobre o produto, mas sim identificar tweets que fazem uma cr√≠tica sobre o produto, seja ela positiva ou negativa. Assim, obt√©m-se uma se√ß√£o de tweets que cont√©m exclusivamente feedbacks sobre o produto, excluindo os tweets que apenas o mencionam, sem sequer avali√°-lo em algum √¢mbito.\n",
    "\n",
    "Para uma futura continua√ß√£o desse projeto, a√≠ ent√£o seria bem conveniente realizar a separa√ß√£o entre cr√≠ticas positivas, negativas e mistas (que apresentam pr√≥s e contras). E ter em m√£os um classificador que descarta coment√°rios que n√£o servem para a aprimora√ß√£o do produto, como o que foi feito nesse projeto, seria extremamente √∫til. Logo, esse projeto deveria continuar sendo financiado, pois para a realiza√ß√£o de uma an√°lise mais focada e espec√≠fica sobre o produto, grande parte do caminho j√° foi andado. Ao final dessa an√°lise dos resultados devolvidos pelo classificador aperfei√ßoado e otimizado, o entendimento de como se d√° a rela√ß√£o dos consumidores com o produto nas diversas situa√ß√µes existentes se mostrar√° bem mais claro e organizado, permitindo ao fabricante mapear quais s√£o as atitudes que devem ser tomadas para melhorar a performance do produto e a sua rela√ß√£o com os consumidores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que n√£o posso alimentar minha base de treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets?\n",
    "\n",
    "Na cria√ß√£o de classificadores, √© bem importante que a quest√£o acima seja levantada para que n√£o haja erros no resultado final. Para respond√™-la, temos que lembrar que o classificador √© feito com base em um conjunto de tweets que s√£o classificados a m√£o, tweet a tweet, esse conjunto √© chamado de treinamento. Quando uma pessoa faz essa sele√ß√£o manual dos tweets, est√° sendo criado no classificador um padr√£o, que √© primariamente regido pela interpreta√ß√£o da pessoa que classificou os tweets, e ao alimentar a minha base de treinamento automaticamente usando o pr√≥prio classificador, restringe-se cada vez mais a base de treinamento a uma classifica√ß√£o padronizada dos tweets, que era adequada para a cole√ß√£o inicial de tweets (classificada manualmente), especificamente para AQUELES tweets, mas que vai diminuindo a flexibilidade do classificador de categorizar novos casos a medida que se alimenta o classificador dessa maneira, em outras palavras, essa pr√°tica ir√° deixar o classificador VICIADO. Por isso n√£o se deve alimentar as bases de treinamento dessa maneira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes cen√°rios:\n",
    "\n",
    "O classificador Naive-Bayes que fizemos nesse projeto pode atuar em diversas situa√ß√µes, seguem algumas delas:\n",
    "\n",
    "* Classifica√ß√£o de artigos em um jornal, indicando o tema geral do artigo a partir dos jarg√µes, manchetes e palavras usadas na not√≠cia. \n",
    "* Classifica√ß√£o de e-mails, onde o classificador poderia identificar e-mails e separ√°-los como spam ou email importante a partir do assunto do email, links que este cont√©m, endere√ßo eletr√¥nico do remetente e palavras usadas. Dividindo assim os emails e facilitando a vida do usu√°rio.\n",
    "* Classifica√ß√£o de artigos cient√≠ficos em sites, identificando as palavras chave de cada mat√©ria. Um exemplo seria um texto que cont√©m o uso recorrente das palavras \"integral\" e \"derivada\", que com os filtros certos, seria identificado como um artigo de √°rea de exatas. Da mesma maneira, um artigo com o uso da palavra \"mitoc√¥ndria\" seria provavelmente classificado como pertencente a √°rea das ci√™ncias biol√≥gicas.\n",
    "___\n",
    "* O seguinte cen√°rio de atua√ß√£o do classificador Naive-Bayes foi retirado do site https://www.datageeks.com.br/naive-bayes/#:~:text=Classifica%C3%A7%C3%A3o%20com%20Naive%20Bayes,-Category%3A%20Machine%20Learning&text=O%20algoritmo%20%E2%80%9CNaive%20Bayes%E2%80%9D%20%C3%A9,provar%20a%20exist%C3%AAncia%20de%20Deus.\n",
    "\n",
    "Um problema simples que exemplifica bem o teorema de Naive-Bayes √© o c√°lculo de probabilidades em cima de diagn√≥stico de doen√ßas.\n",
    "\n",
    "Imagine que estamos trabalhando no diagn√≥stico de uma nova doen√ßa. Ap√≥s realizar testes, coletas e an√°lises com 100 pessoas distintas, descobrimos que 20 pessoas possu√≠am a doen√ßa e 80 pessoas estavam saud√°veis. De todas as pessoas que possu√≠am a doen√ßa, 90% receberam Positivo no teste. J√° 30% das pessoas que n√£o possu√≠am a doen√ßa tamb√©m receberam o teste positivo.\n",
    "\n",
    "A partir destes dados, surge o problema:\n",
    "###### Se uma nova pessoa realizar o teste e receber um resultado positivo, qual a probabilidade dela realmente possuir a doen√ßa?\n",
    "\n",
    "Essa probabilidade a posteriori √© resolvida pelo Naive Bayes. Para isso, √© preciso multiplicar a probabilidade a priori (possuir a doen√ßa) pela probabilidade de ‚Äúreceber um resultado positivo, dado que tem a doen√ßa‚Äù. Com esses dados, tamb√©m podemos calcular a probabilidade a posteriori da nega√ß√£o (n√£o possuir a doen√ßa, dado que recebeu um resultado positivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Melhorias:\n",
    "\n",
    "Embora tenhamos atingido uma boa performance com o nosso classificador, podemos ainda apontar pontos que melhorariam tal performance. Alguns deles s√£o:\n",
    "\n",
    "* Aplicar filtros para descartar palavras que n√£o ser√£o √∫teis para o classificador, como conectivos, artigos, entre outros. Essa remo√ß√£o de palavras in√∫teis poderia ser realizada no momento em que os tweets s√£o transformados em listas de palavras. Evidente que tais palavras s√≥ podem ser consideradas como irrelevantes ou com relev√¢ncia desprez√≠vel para o classificador ap√≥s uma an√°lise cautelosa do meu problema.\n",
    "* Identificar polissemia (diferentes significados para a mesma palavra) e sinon√≠mia (diferentes palavras para o mesmo significado) nos tweets, e para o √∫ltimo caso, buscar abordar tamb√©m as g√≠rias e abrevia√ß√µes comumente utilizadas na internet. Para ter maior no√ß√£o nesse objetivo: https://repositorio.ufscar.br/bitstream/handle/ufscar/7903/LOCHTER_Johannes_2015.pdf?sequence=1&isAllowed=y\n",
    "* Aprofundamento na an√°lise do impacto causado nas probalidades de cada categoria pelos emojis, e saber as dimens√µes da interefer√™ncia desses elementos no meu projeto. Para saber mais: https://www.researchgate.net/profile/Leandro-De-Castro/publication/236161918_Uso_de_Emoticons_para_Analise_de_Sentimento_de_Tweets/links/00b49533d15fbd802d000000/Uso-de-Emoticons-para-Analise-de-Sentimento-de-Tweets.pdf\n",
    "* Inserir mais categorias para melhorar a capacidade de categoriza√ß√£o do classificador, como no lugar de \"Tweets Relevantes\", dividir entre \"Tweets relevantes com cr√≠ticas positivas\" e \"Tweets relevantes com cr√≠ticas negativas\". Para isso, seria preciso realizar mais classifica√ß√µes manuais na base de dados de treinamento do classificador para que este consiga compreender minimamente os dados e probabilidades relativos a cada categoria.\n",
    "* Ap√≥s o aumento de categorias mencionado acima, separar palavras que contenham sarcasmo e dupla nega√ß√£o. Para um melhor entendimento de como proceder nesses dois casos, seguem dois sites que tratam desses assuntos: http://www.each.usp.br/digiampietri/BraSNAM/2015/p12.pdf e http://repositorio.unicamp.br/bitstream/REPOSIP/260283/1/Silva_PauloSergioda_D.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://pypi.org/project/Unidecode/\n",
    "\n",
    "https://www.normaculta.com.br/dupla-negacao/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "https://www.datageeks.com.br/naive-bayes/#:~:text=Classifica%C3%A7%C3%A3o%20com%20Naive%20Bayes,-Category%3A%20Machine%20Learning&text=O%20algoritmo%20%E2%80%9CNaive%20Bayes%E2%80%9D%20%C3%A9,provar%20a%20exist%C3%AAncia%20de%20Deus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
