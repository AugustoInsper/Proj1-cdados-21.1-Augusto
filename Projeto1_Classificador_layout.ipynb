{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Augusto Rocha Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Importando as bibliotecas necess√°rias-----------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Havaianas.xlsx, tudo certo para prosseguir com o projeto!\n"
     ]
    }
   ],
   "source": [
    "#### ----------------------------------Pegando o excel com as classifica√ß√µes manuais dos tweets-------------------------------------\n",
    "\n",
    "filename = 'Havaianas.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com o projeto!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------Definindo Relevantes e Irrelevantes----------------------------------------------------\n",
    "\n",
    "train = pd.read_excel(filename)\n",
    "train_relevante = train[train['Classifica√ß√£o']==1]\n",
    "train_irrelevante = train[train['Classifica√ß√£o']==0]\n",
    "\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_relevante = test[test['Classifica√ß√£o']==1]\n",
    "test_irrelevante = test[test['Classifica√ß√£o']==0]\n",
    "\n",
    "\n",
    "#------------------------------------------Classifica as categorias-------------------------------------------------------------\n",
    "\n",
    "train['Classifica√ß√£o'] = train['Classifica√ß√£o'].astype('category')\n",
    "test['Classifica√ß√£o'] = test['Classifica√ß√£o'].astype('category')\n",
    "\n",
    "train.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']\n",
    "test.Classifica√ß√£o.cat.categories = ['Irrelevante', 'Relevante']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram considerados relevantes os coment√°rios que expressavam uma cr√≠tica sobre o produto, seja ela positiva ou negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para retirada de caracteres indesejado:\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;@/\"\"‚Äú‚Äù,_]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_pronto = re.sub(pattern, '', text)\n",
    "    return text_pronto\n",
    "\n",
    "\n",
    "# Fun√ß√£o para retirada dos acentos nos textos:\n",
    "\n",
    "def tira_acentos(texto):\n",
    "    acentos = {'a':['√°', '√†', '√£', '√¢', '√§'], 'e':['√™', '√©', '√®', '√´'], 'i':['√≠', '√¨', '√Æ', '√Ø'], 'o':['√≥', '√≤', '√¥', '√µ', '√∂'], 'u':['√∫', '√π', '√ª', '√º'], 'c':['√ß']} \n",
    "    for l in acentos:\n",
    "        for e in acentos[l]:\n",
    "            texto = texto.replace(e, l)\n",
    "    return texto\n",
    "\n",
    "\n",
    "#----------------------------Cria uma string com todas as palavras e caracteres da parte de Treinamento-------------------------\n",
    "\n",
    "tweets_train = ''\n",
    "for i in range(len(train)):\n",
    "    tweets_train += train['Treinamento'].loc[i]\n",
    "\n",
    "train_limpo = tira_acentos(cleanup(tweets_train.lower()))    # Deixa a string somente com letras min√∫sculas, retira caracteres\n",
    "                                                             # indesejados e retira os acentos das letras e palavras\n",
    "\n",
    "lista_train = tweet_tokenizer.tokenize(train_limpo)    # Separa os emojis das palavras, e cria uma lista\n",
    "                                                       # em que cada palavra ou emoji √© um elemento            \n",
    "           \n",
    "tabela_t = pd.Series(lista_train).value_counts()       # Faz uma tabela com as frequ√™ncias de cada palavra na lista acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Selecionando tweets de treinamento relevantes e irrelevantes---------------------------------\n",
    "\n",
    "linhas_train_relev = train['Classifica√ß√£o'] == 'Relevante'\n",
    "df_train_relev = train.loc[linhas_train_relev, :]\n",
    "\n",
    "linhas_train_irrelev = train['Classifica√ß√£o'] == 'Irrelevante'\n",
    "df_train_irrelev = train.loc[linhas_train_irrelev, :]\n",
    "\n",
    "#------------------Juntando todos os tweets de treinamento relevantes e irrelevantes cada um numa s√≥ string---------------------\n",
    "\n",
    "tweets_train_relev = ''\n",
    "for i in df_train_relev['Treinamento']:\n",
    "    tweets_train_relev += i\n",
    "\n",
    "tweets_train_irrelev = ''\n",
    "for i in df_train_irrelev['Treinamento']:\n",
    "    tweets_train_irrelev += i\n",
    "\n",
    "    \n",
    "#----------------------------------Tornando as strings criadas acima em listas de palavras--------------------------------------\n",
    "\n",
    "lista_train_relev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_relev.lower())))\n",
    "\n",
    "lista_train_irrelev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_irrelev.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequ√™ncia ABSOLUTA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas    127\n",
      "de            70\n",
      "e             63\n",
      "uma           43\n",
      "a             37\n",
      "            ... \n",
      "amiga          1\n",
      "louca          1\n",
      "internet       1\n",
      "alto           1\n",
      "tanque         1\n",
      "Length: 755, dtype: int64\n",
      "\n",
      "\n",
      "Frequ√™ncia RELATIVA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas    0.069857\n",
      "de           0.038504\n",
      "e            0.034653\n",
      "uma          0.023652\n",
      "a            0.020352\n",
      "               ...   \n",
      "amiga        0.000550\n",
      "louca        0.000550\n",
      "internet     0.000550\n",
      "alto         0.000550\n",
      "tanque       0.000550\n",
      "Length: 755, dtype: float64\n",
      "\n",
      "\n",
      "Frequ√™ncia ABSOLUTA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas         120\n",
      "de                 93\n",
      "e                  73\n",
      "que                43\n",
      "a                  37\n",
      "                 ... \n",
      "medo                1\n",
      "olhando             1\n",
      "pietro              1\n",
      "httpstcobmdxkz      1\n",
      "havaianasmoral      1\n",
      "Length: 1048, dtype: int64\n",
      "\n",
      "\n",
      "Frequ√™ncia RELATIVA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas         0.053074\n",
      "de                0.041132\n",
      "e                 0.032287\n",
      "que               0.019018\n",
      "a                 0.016364\n",
      "                    ...   \n",
      "medo              0.000442\n",
      "olhando           0.000442\n",
      "pietro            0.000442\n",
      "httpstcobmdxkz    0.000442\n",
      "havaianasmoral    0.000442\n",
      "Length: 1048, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#------------------------------Frequ√™ncias para os tweets de treino relevantes--------------------------------------------------\n",
    "\n",
    "tabela_tra = pd.Series(lista_train_relev).value_counts()\n",
    "tabela_trr = pd.Series(lista_train_relev).value_counts(True)\n",
    "\n",
    "print('Frequ√™ncia ABSOLUTA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_tra)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia RELATIVA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_trr)   # tabela printada √† t√≠tulo de consulta, pois n√£o ser√° usada posteriormente\n",
    "\n",
    "\n",
    "#------------------------------Frequ√™ncias para os tweets de treino irrelevantes------------------------------------------------\n",
    "\n",
    "tabela_tia = pd.Series(lista_train_irrelev).value_counts()\n",
    "tabela_tir = pd.Series(lista_train_irrelev).value_counts(True)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia ABSOLUTA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tia)\n",
    "\n",
    "print('\\n\\nFrequ√™ncia RELATIVA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tir)   # tabela printada √† t√≠tulo de consulta, pois n√£o ser√° usada posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classifica√ß√£o\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante\n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante\n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante\n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante\n",
       "4    [menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...     Relevante\n",
       "..                                                 ...           ...\n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante\n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante\n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante\n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante\n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------Limpando os tweets de teste e transformando-os em listas linha a linha--------------------------------\n",
    "\n",
    "teste_em_listas = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test['Teste'])):\n",
    "    teste_em_listas.loc[i, 'Teste'] = tira_acentos(cleanup(test['Teste'][i].lower()))\n",
    "    teste_em_listas.loc[i, 'Teste'] = tweet_tokenizer.tokenize(teste_em_listas.loc[i, 'Teste'])\n",
    "\n",
    "teste_em_listas['Classifica√ß√£o'] = test['Classifica√ß√£o']\n",
    "teste_em_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(tweet, tabela, lista):     # Fun√ß√£o para realizar o c√°lculo de probabilidades das palavras\n",
    "    prob = 1\n",
    "    for palavra in tweet:\n",
    "        if not palavra in tabela:           # Se a palavra de teste n√£o consta em treinamento, ent√£o de acordo com a suaviza√ß√£o\n",
    "            prob = prob / (len(lista) + len(tabela_t)) # de LaPlace, a probabilidade dessa palavra fica com numerador 1\n",
    "        else:\n",
    "            prob = prob * (tabela['%s'%(palavra)] + 1) / (len(lista) + len(tabela_t))\n",
    "    return prob\n",
    "\n",
    "def classificador(tweet):   # Compara a probabilidade de ser relevante com n√£o relevante e devolve a resposta\n",
    "    if probabilidade(tweet, tabela_tra, lista_train_relev) > probabilidade(tweet, tabela_tia, lista_train_irrelev):\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classifica√ß√£o  \\\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante   \n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante   \n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante   \n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante   \n",
       "4    [menina, com, shorts, saia, e, havaianas, ü•∞, ü•∞...     Relevante   \n",
       "..                                                 ...           ...   \n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante   \n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante   \n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante   \n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante   \n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante   \n",
       "\n",
       "     Performance  \n",
       "0      Relevante  \n",
       "1      Relevante  \n",
       "2      Relevante  \n",
       "3      Relevante  \n",
       "4      Relevante  \n",
       "..           ...  \n",
       "195    Relevante  \n",
       "196    Relevante  \n",
       "197    Relevante  \n",
       "198    Relevante  \n",
       "199  Irrelevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Adicionando uma nova coluna ao dataframe Teste--------------------------------------------\n",
    "\n",
    "teste_em_listas['Performance'] = 'NaN'\n",
    "for i in range(len(teste_em_listas)):\n",
    "    teste_em_listas.loc[i, 'Performance'] = classificador(teste_em_listas.loc[i, 'Teste'])\n",
    "teste_em_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Contando o percentual de acertos----------------------------------------------------------\n",
    "\n",
    "contador = 0\n",
    "for i in range(len(teste_em_listas)):\n",
    "    if teste_em_listas.loc[i, 'Classifica√ß√£o'] == teste_em_listas.loc[i, 'Performance']:\n",
    "        contador += 1\n",
    "contador = contador / len(teste_em_listas)\n",
    "    \n",
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Performance</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Performance    Irrelevante  Relevante    All\n",
       "Classifica√ß√£o                               \n",
       "Irrelevante           0.28      0.265  0.545\n",
       "Relevante             0.11      0.345  0.455\n",
       "All                   0.39      0.610  1.000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------Dashboard para an√°lise de sentimento e visualiza√ß√£o de dados-------------------------------------------\n",
    "\n",
    "quadro = pd.crosstab(teste_em_listas['Classifica√ß√£o'], teste_em_listas['Performance'], margins = True, normalize = True)\n",
    "quadro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela acima, √© poss√≠vel ver que obtemos os seguintes valores:\n",
    "* Verdadeiros positivos (mensagens relevantes e que s√£o classificadas como relevantes): 34,5%\n",
    "* Falsos positivos (mensagens irrelevantes e que s√£o classificadas como relevantes): 26,5%\n",
    "* Verdadeiros negativos (mensagens irrelevantes e que s√£o classificadas como irrelevantes): 28%\n",
    "* Falsos negativos (mensagens relevantes e que s√£o classificadas como irrelevantes): 11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total de ACERTOS do classificador: 62,5%\n",
    "* Total de ERROS do classificador: 37,5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes cen√°rios:\n",
    "\n",
    "* Classifica√ß√£o de artigos em um jornal, indicando o tema do artigo por meio do uso de jarg√µes e o tipo de reportagem. \n",
    "* Classifica√ß√£o de e-mails, onde o classificador poderia indentificar e-mails e separa-lo como spam ou email importantes, dividindo-os e facilitando a vida do usu√°rio.\n",
    "* Classifica√ß√£o de artigos cient√≠ficos em materias, indentificando as palavras chave de cada materia. Um exemplo seria um texto com a palavra \"integral\", onde, com os filtros certos, seria indentificada como artigo de matem√°tica ou f√≠sica.\n",
    "\n",
    "\n",
    "## Melhorias:\n",
    "* Aplicar filtros para descartar palavras que n√£o ser√£o √∫teis para o classificador, como conectivos e artigos.\n",
    "* Aplicar uma fun√ß√£o que classifique as frases em frases relevantes negativas e positivas, al√©m de separar palavras que contenham sarcasmo indentificando palavras negativas na mesma frase.\n",
    "* Aplicar mais categorias para melhorar a efici√™ncia do classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://pypi.org/project/Unidecode/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
