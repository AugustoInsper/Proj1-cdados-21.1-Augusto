{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Augusto Rocha Ribeiro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------Importando as bibliotecas necessárias-----------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Havaianas.xlsx, tudo certo para prosseguir com o projeto!\n"
     ]
    }
   ],
   "source": [
    "#### ----------------------------------Pegando o excel com as classificações manuais dos tweets-------------------------------------\n",
    "\n",
    "filename = 'Havaianas.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com o projeto!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------Definindo Relevantes e Irrelevantes----------------------------------------------------\n",
    "\n",
    "train = pd.read_excel(filename)\n",
    "train_relevante = train[train['Classificação']==1]\n",
    "train_irrelevante = train[train['Classificação']==0]\n",
    "\n",
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_relevante = test[test['Classificação']==1]\n",
    "test_irrelevante = test[test['Classificação']==0]\n",
    "\n",
    "\n",
    "#------------------------------------------Classifica as categorias-------------------------------------------------------------\n",
    "\n",
    "train['Classificação'] = train['Classificação'].astype('category')\n",
    "test['Classificação'] = test['Classificação'].astype('category')\n",
    "\n",
    "train.Classificação.cat.categories = ['Irrelevante', 'Relevante']\n",
    "test.Classificação.cat.categories = ['Irrelevante', 'Relevante']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram considerados relevantes os comentários que expressavam uma crítica sobre o produto, seja ela positiva ou negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retirada de caracteres indesejado:\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;@/\"\"“”,_]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_pronto = re.sub(pattern, '', text)\n",
    "    return text_pronto\n",
    "\n",
    "\n",
    "# Função para retirada dos acentos nos textos:\n",
    "\n",
    "def tira_acentos(texto):\n",
    "    acentos = {'a':['á', 'à', 'ã', 'â', 'ä'], 'e':['ê', 'é', 'è', 'ë'], 'i':['í', 'ì', 'î', 'ï'], 'o':['ó', 'ò', 'ô', 'õ', 'ö'], 'u':['ú', 'ù', 'û', 'ü'], 'c':['ç']} \n",
    "    for l in acentos:\n",
    "        for e in acentos[l]:\n",
    "            texto = texto.replace(e, l)\n",
    "    return texto\n",
    "\n",
    "\n",
    "#----------------------------Cria uma string com todas as palavras e caracteres da parte de Treinamento-------------------------\n",
    "\n",
    "tweets_train = ''\n",
    "for i in range(len(train)):\n",
    "    tweets_train += train['Treinamento'].loc[i]\n",
    "\n",
    "train_limpo = tira_acentos(cleanup(tweets_train.lower()))    # Deixa a string somente com letras minúsculas, retira caracteres\n",
    "                                                             # indesejados e retira os acentos das letras e palavras\n",
    "\n",
    "lista_train = tweet_tokenizer.tokenize(train_limpo)    # Separa os emojis das palavras, e cria uma lista\n",
    "                                                       # em que cada palavra ou emoji é um elemento            \n",
    "           \n",
    "tabela_t = pd.Series(lista_train).value_counts()       # Faz uma tabela com as frequências de cada palavra na lista acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Selecionando tweets de treinamento relevantes e irrelevantes---------------------------------\n",
    "\n",
    "linhas_train_relev = train['Classificação'] == 'Relevante'\n",
    "df_train_relev = train.loc[linhas_train_relev, :]\n",
    "\n",
    "linhas_train_irrelev = train['Classificação'] == 'Irrelevante'\n",
    "df_train_irrelev = train.loc[linhas_train_irrelev, :]\n",
    "\n",
    "#------------------Juntando todos os tweets de treinamento relevantes e irrelevantes cada um numa só string---------------------\n",
    "\n",
    "tweets_train_relev = ''\n",
    "for i in df_train_relev['Treinamento']:\n",
    "    tweets_train_relev += i\n",
    "\n",
    "tweets_train_irrelev = ''\n",
    "for i in df_train_irrelev['Treinamento']:\n",
    "    tweets_train_irrelev += i\n",
    "\n",
    "    \n",
    "#----------------------------------Tornando as strings criadas acima em listas de palavras--------------------------------------\n",
    "\n",
    "lista_train_relev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_relev.lower())))\n",
    "\n",
    "lista_train_irrelev = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_train_irrelev.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequência ABSOLUTA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas    127\n",
      "de            70\n",
      "e             63\n",
      "uma           43\n",
      "a             37\n",
      "            ... \n",
      "estourou       1\n",
      "veludo         1\n",
      "boart          1\n",
      "saco           1\n",
      "alto           1\n",
      "Length: 755, dtype: int64\n",
      "\n",
      "\n",
      "Frequência RELATIVA das palavras dos tweets RELEVANTES\n",
      "\n",
      "havaianas    0.069857\n",
      "de           0.038504\n",
      "e            0.034653\n",
      "uma          0.023652\n",
      "a            0.020352\n",
      "               ...   \n",
      "estourou     0.000550\n",
      "veludo       0.000550\n",
      "boart        0.000550\n",
      "saco         0.000550\n",
      "alto         0.000550\n",
      "Length: 755, dtype: float64\n",
      "\n",
      "\n",
      "Frequência ABSOLUTA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas    120\n",
      "de            93\n",
      "e             73\n",
      "que           43\n",
      "a             37\n",
      "            ... \n",
      "santos         1\n",
      "fotos          1\n",
      "tbmve          1\n",
      "next           1\n",
      "etc            1\n",
      "Length: 1048, dtype: int64\n",
      "\n",
      "\n",
      "Frequência RELATIVA das palavras dos tweets IRRELEVANTES\n",
      "\n",
      "havaianas    0.053074\n",
      "de           0.041132\n",
      "e            0.032287\n",
      "que          0.019018\n",
      "a            0.016364\n",
      "               ...   \n",
      "santos       0.000442\n",
      "fotos        0.000442\n",
      "tbmve        0.000442\n",
      "next         0.000442\n",
      "etc          0.000442\n",
      "Length: 1048, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#------------------------------Frequências para os tweets de treino relevantes--------------------------------------------------\n",
    "\n",
    "tabela_tra = pd.Series(lista_train_relev).value_counts()\n",
    "tabela_trr = pd.Series(lista_train_relev).value_counts(True)\n",
    "\n",
    "print('Frequência ABSOLUTA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_tra)\n",
    "\n",
    "print('\\n\\nFrequência RELATIVA das palavras dos tweets RELEVANTES\\n')\n",
    "print(tabela_trr)   # tabela printada à título de consulta, pois não será usada posteriormente\n",
    "\n",
    "\n",
    "#------------------------------Frequências para os tweets de treino irrelevantes------------------------------------------------\n",
    "\n",
    "tabela_tia = pd.Series(lista_train_irrelev).value_counts()\n",
    "tabela_tir = pd.Series(lista_train_irrelev).value_counts(True)\n",
    "\n",
    "print('\\n\\nFrequência ABSOLUTA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tia)\n",
    "\n",
    "print('\\n\\nFrequência RELATIVA das palavras dos tweets IRRELEVANTES\\n')\n",
    "print(tabela_tir)   # tabela printada à título de consulta, pois não será usada posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, 🥰, 🥰...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classificação\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante\n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante\n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante\n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante\n",
       "4    [menina, com, shorts, saia, e, havaianas, 🥰, 🥰...     Relevante\n",
       "..                                                 ...           ...\n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante\n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante\n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante\n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante\n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------Limpando os tweets de teste e transformando-os em listas linha a linha--------------------------------\n",
    "\n",
    "teste_em_listas = pd.DataFrame()\n",
    "\n",
    "for i in range(len(test['Teste'])):\n",
    "    teste_em_listas.loc[i, 'Teste'] = tira_acentos(cleanup(test['Teste'][i].lower()))\n",
    "    teste_em_listas.loc[i, 'Teste'] = tweet_tokenizer.tokenize(teste_em_listas.loc[i, 'Teste'])\n",
    "\n",
    "teste_em_listas['Classificação'] = test['Classificação']\n",
    "teste_em_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicação dos parâmetros usados nas seguintes funções:\n",
    "#   tab_abs: tabela de frequências absolutas\n",
    "#   lista_de_pal: lista de palavras que será usada\n",
    "#   tab_tds_palavras: tabela que contém todas as palavras possíveis\n",
    "#   tab_abs_rel: tabela de frequências absolutas para os tweets relevantes\n",
    "#   tab_abs_irr: tabela de frequências absolutas para os tweets irrelevantes\n",
    "#   lista_rel: lista de palavras dos tweets relevantes\n",
    "#   lista_irr: lista de palavras dos tweets irrelevantes\n",
    "\n",
    "\n",
    "# Função para realizar o cálculo de probabilidades das palavras\n",
    "\n",
    "def probabilidade_tweet(tweet, tab_abs, lista_de_pal, tab_tds_palavras):\n",
    "    prob = 1\n",
    "    for palavra in tweet:\n",
    "        if not palavra in tab_abs:                                      # Se a palavra de teste não consta em treinamento,\n",
    "            prob = prob / (len(lista_de_pal) + len(tab_tds_palavras))   # então de acordo com a suavização de LaPlace\n",
    "                                                                        # a probabilidade dessa palavra fica com numerador 1\n",
    "        else:\n",
    "            prob = prob * (tab_abs['%s'%(palavra)] + 1) / (len(lista_de_pal) + len(tab_tds_palavras))\n",
    "    return prob\n",
    "\n",
    "\n",
    "# Função que compara a probabilidade de ser relevante com não relevante e devolve a resposta:\n",
    "\n",
    "def classifica(tweet, tab_abs_rel, tab_abs_irr, lista_rel, lista_irr, tab_tds_palavras):\n",
    "    if probabilidade_tweet(tweet, tab_abs_rel, lista_rel, tab_tds_palavras) > probabilidade_tweet(tweet, tab_abs_irr, lista_irr, tab_tds_palavras):\n",
    "        return 'Relevante'\n",
    "    else:\n",
    "        return 'Irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joshnaku, delicia, perfeito, minecraft, chine...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[vendese, foto, dos, meus, pes, feios, com, ma...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rt, ribeirod, 10, nao, vejo, a, hora, de, che...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[estou, indo, de, havaiana, eu, tem, problema,...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[menina, com, shorts, saia, e, havaianas, 🥰, 🥰...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[egirao, aeciodepapelao, mas, a, tv, e, uma, u...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[todo, mundo, q, for, vir, no, meu, aniversari...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[eu, prometi, pra, mim, mesmo, que, eu, nao, i...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[eu, sempre, tive, toque, com, havaianas, bran...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[oi, vcs, sao, reais, manda, foto, da, sua, ha...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste Classificação  \\\n",
       "0    [joshnaku, delicia, perfeito, minecraft, chine...     Relevante   \n",
       "1    [vendese, foto, dos, meus, pes, feios, com, ma...     Relevante   \n",
       "2    [rt, ribeirod, 10, nao, vejo, a, hora, de, che...     Relevante   \n",
       "3    [estou, indo, de, havaiana, eu, tem, problema,...     Relevante   \n",
       "4    [menina, com, shorts, saia, e, havaianas, 🥰, 🥰...     Relevante   \n",
       "..                                                 ...           ...   \n",
       "195  [egirao, aeciodepapelao, mas, a, tv, e, uma, u...   Irrelevante   \n",
       "196  [todo, mundo, q, for, vir, no, meu, aniversari...     Relevante   \n",
       "197  [eu, prometi, pra, mim, mesmo, que, eu, nao, i...     Relevante   \n",
       "198  [eu, sempre, tive, toque, com, havaianas, bran...   Irrelevante   \n",
       "199  [oi, vcs, sao, reais, manda, foto, da, sua, ha...   Irrelevante   \n",
       "\n",
       "     Performance  \n",
       "0      Relevante  \n",
       "1      Relevante  \n",
       "2      Relevante  \n",
       "3      Relevante  \n",
       "4      Relevante  \n",
       "..           ...  \n",
       "195    Relevante  \n",
       "196    Relevante  \n",
       "197    Relevante  \n",
       "198    Relevante  \n",
       "199  Irrelevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Adicionando uma nova coluna ao dataframe Teste--------------------------------------------\n",
    "\n",
    "teste_em_listas['Performance'] = 'NaN'\n",
    "for i in range(len(teste_em_listas)):\n",
    "    teste_em_listas.loc[i, 'Performance'] = classifica(teste_em_listas.loc[i, 'Teste'], tabela_tra, tabela_tia, lista_train_relev, lista_train_irrelev, tabela_t)\n",
    "teste_em_listas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-------------------------------------Contando o percentual de acertos----------------------------------------------------------\n",
    "\n",
    "contador = 0\n",
    "for i in range(len(teste_em_listas)):\n",
    "    if teste_em_listas.loc[i, 'Classificação'] == teste_em_listas.loc[i, 'Performance']:\n",
    "        contador += 1\n",
    "contador = contador / len(teste_em_listas)\n",
    "    \n",
    "contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Performance</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Performance    Irrelevante  Relevante    All\n",
       "Classificação                               \n",
       "Irrelevante           0.28      0.265  0.545\n",
       "Relevante             0.11      0.345  0.455\n",
       "All                   0.39      0.610  1.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------------Dashboard para análise de sentimento e visualização de dados-------------------------------------------\n",
    "\n",
    "quadro = pd.crosstab(teste_em_listas['Classificação'], teste_em_listas['Performance'], margins = True, normalize = True)\n",
    "quadro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando a tabela acima, é possível ver que obtemos as seguintes porcentagens:\n",
    "* Verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes): 34,5%\n",
    "* Falsos positivos (mensagens irrelevantes e que são classificadas como relevantes): 26,5%\n",
    "* Verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes): 28%\n",
    "* Falsos negativos (mensagens relevantes e que são classificadas como irrelevantes): 11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca que será usada nessa seção do projeto:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = pd.read_excel(filename, sheet_name = 'Todos')                # dataframe com os 500 tweets juntos\n",
    "lista_percentuais = []                                   # lista que servirá para montar o histograma\n",
    "\n",
    "\n",
    "# Abaixo, foi feita uma função que devolve o percentual de acertos para cada nova separação dos tweets entre\n",
    "# Treinamento e Teste. Por essa função sintetizar o que foi trabalhado ao longo desse jupyter notebook,\n",
    "# a maioria dos comandos nela presentes já foram explicados nas células acima.\n",
    "\n",
    "def devolve_percentual_de_acertos(df):\n",
    "    df_train, df_test = train_test_split(df, train_size=0.6)    # Separação de maneira aleatória dos tweets entre\n",
    "                                                                # Treinamento e Teste, sendo que a parte de Treinamento\n",
    "                                                                # fica com 60% dos tweets e a parte de Teste fica com 40%\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)    # Resetando os índices das linhas do dataframe para facilitar a sua\n",
    "    df_test = df_test.reset_index(drop=True)      # manipulação. Os índices nesse caso não são importantes.\n",
    "    \n",
    "    df_train_relevante = df_train[df_train['Classificação']==1]\n",
    "    df_train_irrelevante = df_train[df_train['Classificação']==0]\n",
    "\n",
    "    df_test_relevante = df_test[df_test['Classificação']==1]\n",
    "    df_test_irrelevante = df_test[df_test['Classificação']==0]\n",
    "    \n",
    "    df_train['Classificação'] = df_train['Classificação'].astype('category')\n",
    "    df_test['Classificação'] = df_test['Classificação'].astype('category')\n",
    "\n",
    "    df_train.Classificação.cat.categories = ['Irrelevante', 'Relevante']\n",
    "    df_test.Classificação.cat.categories = ['Irrelevante', 'Relevante']\n",
    "\n",
    "    tweets_df_train = ''\n",
    "    for i in range(len(df_train)):\n",
    "        tweets_df_train += df_train['Tweet'].loc[i]\n",
    "\n",
    "    df_train_limpo = tira_acentos(cleanup(tweets_df_train.lower()))\n",
    "    lista_df_train = tweet_tokenizer.tokenize(df_train_limpo)\n",
    "           \n",
    "    tab_t = pd.Series(lista_df_train).value_counts()\n",
    "    \n",
    "    linhas_df_train_rel = df_train['Classificação'] == 'Relevante'\n",
    "    df_train_rel = df_train.loc[linhas_df_train_rel, :]\n",
    "\n",
    "    linhas_df_train_irr = df_train['Classificação'] == 'Irrelevante'\n",
    "    df_train_irr = df_train.loc[linhas_df_train_irr, :]\n",
    "\n",
    "    tweets_df_train_rel = ''\n",
    "    for i in df_train_rel['Tweet']:\n",
    "        tweets_df_train_rel += i\n",
    "\n",
    "    tweets_df_train_irr = ''\n",
    "    for i in df_train_irr['Tweet']:\n",
    "        tweets_df_train_irr += i\n",
    "\n",
    "    lista_df_train_rel = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_df_train_rel.lower())))\n",
    "    lista_df_train_irr = tweet_tokenizer.tokenize(tira_acentos(cleanup(tweets_df_train_irr.lower())))\n",
    "    \n",
    "    tab_tra = pd.Series(lista_df_train_rel).value_counts()\n",
    "    tab_tia = pd.Series(lista_df_train_irr).value_counts()\n",
    "    \n",
    "    \n",
    "    df_test_em_listas = pd.DataFrame()\n",
    "    for i in range(len(df_test['Tweet'])):\n",
    "        df_test_em_listas.loc[i, 'Tweet'] = tira_acentos(cleanup(df_test['Tweet'][i].lower()))\n",
    "        df_test_em_listas.loc[i, 'Tweet'] = tweet_tokenizer.tokenize(df_test_em_listas.loc[i, 'Tweet'])\n",
    "    df_test_em_listas['Classificação'] = df_test['Classificação']\n",
    "    \n",
    "    df_test_em_listas['Performance'] = 'NaN'\n",
    "    for i in range(len(df_test_em_listas)):\n",
    "        df_test_em_listas.loc[i, 'Performance'] = classifica(df_test_em_listas.loc[i, 'Tweet'], tab_tra, tab_tia, lista_df_train_rel, lista_df_train_irr, tab_t)\n",
    "    \n",
    "    percentual_de_acertos = 0\n",
    "    for i in range(len(df_test_em_listas)):\n",
    "        if df_test_em_listas.loc[i, 'Classificação'] == df_test_em_listas.loc[i, 'Performance']:\n",
    "            percentual_de_acertos += 1\n",
    "    percentual_de_acertos = percentual_de_acertos / len(df_test_em_listas)\n",
    "    \n",
    "    return percentual_de_acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetindo a função definida acima 100 vezes para coletar valores de percentual\n",
    "# de acertos e ir adicionando-os um a um na minha lista\n",
    "\n",
    "for i in range(100):\n",
    "    lista_percentuais.append(devolve_percentual_de_acertos(todos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construção do histograma usando a lista com os percentuais de acertos para cada uma das 100 vezes em que a função\n",
    "# \"devolve_percentual_de_acertos()\" foi executada, foram usadas 15 faixas nesse histograma.\n",
    "\n",
    "plt.hist(lista_percentuais, bins=15, edgecolor='white')\n",
    "plt.title('Histograma para várias separações dos tweets entre Treinamento e Teste')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xlabel('Percentuais de acertos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem média de acertos do meu classificador: 58.46 %\n"
     ]
    }
   ],
   "source": [
    "print('Porcentagem média de acertos do meu classificador:', (np.mean(lista_percentuais)*100).round(2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que o classificador teve uma porcentagem média de acertos de 58,46% (e de 62,5% na primeira tentativa), é correto dizer que ele teve uma performance moderada para boa. Para tal resultado, foram essenciais algumas manipulações, como a suavização de Laplace, remoção de caracteres indesejados (emojis são mantidos), correção de espaços entre palavras e emojis e entre os próprios emojis, e a remoção de acentos das letras, sendo a última, uma manipulação extra feita por mim.\n",
    "\n",
    "Embora tenha funções de bibliotecas do python que façam a remoção de acentos das letras, eu mesmo fiz a minha função porque funções como unidecode() além de retirar os acentos, também removem os emojis, o que não é o nosso foco nesse classificador. Então, o que foi feito na minha função foi identificar as letras que continham acentos e usar a função replace() para substituí-las pelas suas respectivas letras sem o acento. Os acentos considerados aqui foram o agudo, o circunflexo, o til, o grave e o trema para as vogais, e o cedilha para a letra \"c\".\n",
    "\n",
    "Analisando a última tabela cruzada printada, vemos que a porcentagem de falsos positivos está bem maior que a de falsos negativos, a partir dessa informação, é importante nos perguntarmos e analisarmos se o nosso classificador está tendencioso a classificar os tweets como relevantes. Assim, é sempre importante reconhecer que ainda é possível realizar algumas melhorias no classificador em questão.\n",
    "\n",
    "#### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste:\n",
    "A partir do histograma plotado acima, é fundamental que vejamos, na construção de um classificador, a importância de se considerar várias divisões da base de dados em Treinamento e Teste, pois assim conseguimos ter uma maior noção sobre o valor para o qual o percentual de acertos do meu classificador tende. Não conseguir essa ampla visão da real performance do meu classificador, já que toda a avaliação deste acaba sendo feita com base em uma única separação dos tweets entre Treinamento e Teste, se mostra como uma grande desvantagem para a construção de um classificador que considera apenas uma única divisão da base de dados em treinamento e em teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dupla negação e sarcasmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duas características sintáticas da língua portuguesa que são mais passíveis de classificação incorreta por parte de classificadores é a dupla negação e o sarcasmo. Por serem particularidades sintáticas consagradas pelo uso, fica mais difícil atribuir ao classificador a \"interpretação\" necessária para compreendê-las.\n",
    "\n",
    "Essas duas características provavelmente causariam mais confusão numa situação em que se busca classificar frases positivas e negativas sobre algo, pois em frases que contenham essas figuras da linguagem, o classificador identificaria as frases como uma categoria oposta (sendo \"positivo\" oposto de \"negativo\") ao que elas realmente são, justamente por causa das peculiaridades que a dupla negação e o sarcasmo apresentam.\n",
    "\n",
    "No nosso caso, felizmente, essa confusão não se faz tão presente pois aqui o que almejamos não é classificar tweets em positivos e negativos sobre o produto, mas sim identificar tweets que fazem uma crítica sobre o produto, seja ela positiva ou negativa. Assim, obtém-se uma seção de tweets que contém exclusivamente feedbacks sobre o produto, excluindo os tweets que apenas o mencionam, sem sequer avaliá-lo em algum âmbito.\n",
    "\n",
    "Para uma futura continuação desse projeto, aí então seria bem conveniente realizar a separação entre críticas positivas, negativas e mistas (que apresentam prós e contras). E ter em mãos um classificador que descarta comentários que não servem para a aprimoração do produto, como o que foi feito nesse projeto, seria extremamente útil. Logo, esse projeto deveria continuar sendo financiado, pois para a realização de uma análise mais focada e específica sobre o produto, grande parte do caminho já foi andado. Ao final dessa análise dos resultados devolvidos pelo classificador aperfeiçoado e otimizado, o entendimento de como se dá a relação dos consumidores com o produto nas diversas situações existentes se mostrará bem mais claro e organizado, permitindo ao fabricante mapear quais são as atitudes que devem ser tomadas para melhorar a performance do produto e a sua relação com os consumidores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que não posso alimentar minha base de treinamento automaticamente usando o próprio classificador, aplicado a novos tweets?\n",
    "\n",
    "Na criação de classificadores, é bem importante que a questão acima seja levantada para que não haja erros no resultado final. Para respondê-la, temos que lembrar que o classificador é feito com base em um conjunto de tweets que são classificados a mão, tweet a tweet, esse conjunto é chamado de treinamento. Quando uma pessoa faz essa seleção manual dos tweets, está sendo criado no classificador um padrão, que é primariamente regido pela interpretação da pessoa que classificou os tweets, e ao alimentar a minha base de treinamento automaticamente usando o próprio classificador, restringe-se cada vez mais a base de treinamento a uma classificação padronizada dos tweets, que era adequada para a coleção inicial de tweets (classificada manualmente), especificamente para AQUELES tweets, mas que vai diminuindo a flexibilidade do classificador de categorizar novos casos a medida que se alimenta o classificador dessa maneira, em outras palavras, essa prática irá deixar o classificador VICIADO. Por isso não se deve alimentar as bases de treinamento dessa maneira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes cenários:\n",
    "\n",
    "O classificador Naive-Bayes que fizemos nesse projeto pode atuar em diversas situações, seguem algumas delas:\n",
    "\n",
    "* Classificação de artigos em um jornal, indicando o tema geral do artigo a partir dos jargões, manchetes e palavras usadas na notícia. \n",
    "* Classificação de e-mails, onde o classificador poderia identificar e-mails e separá-los como spam ou email importante a partir do assunto do email, links que este contém, endereço eletrônico do remetente e palavras usadas. Dividindo assim os emails e facilitando a vida do usuário.\n",
    "* Classificação de artigos científicos em sites, identificando as palavras chave de cada matéria. Um exemplo seria um texto que contém o uso recorrente das palavras \"integral\" e \"derivada\", que com os filtros certos, seria identificado como um artigo de área de exatas. Da mesma maneira, um artigo com o uso da palavra \"mitocôndria\" seria provavelmente classificado como pertencente a área das ciências biológicas.\n",
    "\n",
    "\n",
    "## Melhorias:\n",
    "\n",
    "Embora tenhamos atingido uma boa performance com o nosso classificador, podemos ainda apontar pontos que melhorariam tal performance. Alguns deles são:\n",
    "\n",
    "* Aplicar filtros para descartar palavras que não serão úteis para o classificador, como conectivos, artigos, entre outros. Essa remoção de palavras inúteis poderia ser realizada no momento em que os tweets são transformados em listas de palavras. Evidente que tais palavras só podem ser consideradas como irrelevantes ou com relevância desprezível para o classificador após uma análise cautelosa do meu problema.\n",
    "* Identificar polissemia (diferentes significados para a mesma palavra) e sinonímia (diferentes palavras para o mesmo significado) nos tweets. Para ter maior noção nesse objetivo: https://repositorio.ufscar.br/bitstream/handle/ufscar/7903/LOCHTER_Johannes_2015.pdf?sequence=1&isAllowed=y\n",
    "* Aprofundamento na análise do impacto causado nas probalidades de cada categoria pelos emojis, e saber as dimensões da intereferência desses elementos no meu projeto. Para saber mais: https://www.researchgate.net/profile/Leandro-De-Castro/publication/236161918_Uso_de_Emoticons_para_Analise_de_Sentimento_de_Tweets/links/00b49533d15fbd802d000000/Uso-de-Emoticons-para-Analise-de-Sentimento-de-Tweets.pdf\n",
    "* Inserir mais categorias para melhorar a capacidade de categorização do classificador, como no lugar de \"Tweets Relevantes\", dividir entre \"Tweets relevantes com críticas positivas\" e \"Tweets relevantes com críticas negativas\". Para isso, seria preciso realizar mais classificações manuais na base de dados de treinamento do classificador para que este consiga compreender minimamente os dados e probabilidades relativos a cada categoria.\n",
    "* Após o aumento de categorias mencionado acima, separar palavras que contenham sarcasmo e dupla negação. Para um melhor entendimento de como proceder nesses dois casos, seguem dois sites que tratam desses assuntos: http://www.each.usp.br/digiampietri/BraSNAM/2015/p12.pdf e http://repositorio.unicamp.br/bitstream/REPOSIP/260283/1/Silva_PauloSergioda_D.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**\n",
    "\n",
    "https://pypi.org/project/Unidecode/\n",
    "\n",
    "https://www.normaculta.com.br/dupla-negacao/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
